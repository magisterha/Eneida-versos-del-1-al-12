import streamlit as st
import google.generativeai as genai
import requests

# 1. DICCIONARIO DE TRADUCCIONES (Mantenemos tu estructura multilingÃ¼e)
TRADUCCIONES = {
    "EspaÃ±ol": {
        "sidebar_title": "ğŸ›ï¸ ConfiguraciÃ³n",
        "lang_label": "Idioma del Tutor:",
        "reset_btn": "ğŸ”„ Reiniciar Consulta",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Consulta FilolÃ³gica Libre",
        "welcome": "### ğŸ›ï¸ Â¡Salve!\nHe configurado mi sistema para ayudarte en **EspaÃ±ol**. Â¿QuÃ© palabra o verso deseas analizar?",
        "input_placeholder": "PregÃºntale a la IA (ej. cano, arma, virum...)",
        "spinner": "Analizando bajo contexto...",
        "error_api": "ğŸ›ï¸ El orÃ¡culo estÃ¡ saturado o ha habido un error de conexiÃ³n. Reintenta en breve.",
        "sticky_note": "ğŸ“ Texto fijo para consulta permanente.",
        "cta_btn": "ğŸ›ï¸ Reserva una clase con un profesor de latÃ­n"
    },
    "English": {
        "sidebar_title": "ğŸ›ï¸ Settings",
        "lang_label": "Tutor Language:",
        "reset_btn": "ğŸ”„ Reset Chat",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Free Philological Consultation",
        "welcome": "### ğŸ›ï¸ Salve!\nI have configured my system to help you in **English**. Which word or verse would you like to analyze?",
        "input_placeholder": "Ask the AI (e.g., cano, arma, virum...)",
        "spinner": "Analyzing contextually...",
        "error_api": "ğŸ›ï¸ The oracle is busy or there was a connection error. Please try again.",
        "sticky_note": "ğŸ“ Static text for permanent reference.",
        "cta_btn": "ğŸ›ï¸ Book a class with a Latin teacher"
    },
    "Latine": {
        "sidebar_title": "ğŸ›ï¸ Configuratio",
        "lang_label": "Lingua Tutoris:",
        "reset_btn": "ğŸ”„ Iterare Colloquium",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Colloquium Philologicum Liberum",
        "welcome": "### ğŸ›ï¸ Salve!\nSÄ«stÄ“ma meum parÄvÄ« ut **LatinÄ“** tÄ“ adiuvÄrem. Quod verbum aut versum explÅrÄre vÄ«s?",
        "input_placeholder": "InterrogÄ aliquid (ex. cano, arma, virum...)",
        "spinner": "ExquÄ«rentem...",
        "error_api": "ğŸ›ï¸ ÅŒrÄculum occupÄtum est. PaulÅ post sevÄ“rÄ.",
        "sticky_note": "ğŸ“ Textus fÄ«xus ad perpetuam cÅnsultÄtiÅnem.",
        "cta_btn": "ğŸ›ï¸ Scholam cum magistro linguae Latinae reserva"
    },
    "ç¹é«”ä¸­æ–‡ (Taiwan)": {
        "sidebar_title": "ğŸ›ï¸ è¨­å®š",
        "lang_label": "å°å¸«èªè¨€ï¼š",
        "reset_btn": "ğŸ”„ é‡ç½®å°è©±",
        "header": "ç¶­å‰çˆ¾ï¼šã€ŠåŸƒæ¶…é˜¿æ–¯ç´€ã€‹(I, 1-11)",
        "chat_header": "ğŸ’¬ è‡ªç”±æ–‡ç»å­¸è«®è©¢",
        "welcome": "### ğŸ›ï¸ æ‚¨å¥½ (Salve)ï¼\næˆ‘å·²æº–å‚™å¥½ä»¥ **ç¹é«”ä¸­æ–‡** ç‚ºæ‚¨æä¾›å¹«åŠ©ã€‚æ‚¨æƒ³åˆ†ææ–‡ä¸­çš„å“ªå€‹è©æˆ–å“ªä¸€è¡Œï¼Ÿ",
        "input_placeholder": "å‘ AI è©¢å•ï¼ˆä¾‹å¦‚ï¼šcano, arma, virum...ï¼‰",
        "spinner": "æ­£åœ¨é€²è¡Œèªå¢ƒåˆ†æ...",
        "error_api": "ğŸ›ï¸ ç¥è«­ç›®å‰ç¹å¿™ã€‚è«‹ç¨å¾Œå†è©¦ã€‚",
        "sticky_note": "ğŸ“ æ–‡æœ¬å·²å›ºå®šï¼Œæ–¹ä¾¿éš¨æ™‚æŸ¥é–±ã€‚",
        "cta_btn": "ğŸ›ï¸ èˆ‡æ‹‰ä¸èªè€å¸«é ç´„èª²ç¨‹"
    }
}

# 2. CONFIGURACIÃ“N DE PÃGINA Y CSS
st.set_page_config(page_title="Aeneis Tutor AI", layout="wide")

st.markdown("""
    <style>
    [data-testid="column"]:nth-of-type(1) { position: sticky; top: 2rem; align-self: flex-start; }
    .verse-line { font-family: 'Times New Roman', serif; font-size: 1.4rem; line-height: 1.7; color: #2c3e50; margin-bottom: 5px; }
    .main-header { color: #8e44ad; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# 3. SIDEBAR
with st.sidebar:
    idioma_app = st.selectbox("Language / Idioma / èªè¨€", list(TRADUCCIONES.keys()))
    t = TRADUCCIONES[idioma_app]
    st.title(t["sidebar_title"])
    if st.button(t["reset_btn"]):
        st.session_state.messages = []
        st.rerun()

# 4. CARGA DE PROMPT Y CONFIGURACIÃ“N DE MODELO
@st.cache_data
def load_prompt(url):
    try:
        r = requests.get(url)
        return r.text if r.status_code == 200 else "Expert Latin Philologist Role."
    except: return "Expert Latin Philologist Role."

PROMPT_URL = "https://raw.githubusercontent.com/tu_usuario/tu_repo/main/prompt_maestro.txt"
sys_instruction = load_prompt(PROMPT_URL)

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash-lite-preview-02-05", #
        system_instruction=sys_instruction
    )
else:
    st.error("âš ï¸ API KEY missing in Secrets.")
    st.stop()

# 5. DISEÃ‘O DE INTERFAZ
col_txt, col_chat = st.columns([1, 1], gap="large")

with col_txt:
    st.markdown(f"<h2 class='main-header'>{t['header']}</h2>", unsafe_allow_html=True)
    st.write("---")
    versos = ["1. Arma virumque canÅ, TrÅiae quÄ« prÄ«mus ab ÅrÄ«s", "2. Äªtaliam, fÄtÅ profugus, LÄvÄ«niaque vÄ“nit", "3. lÄ«tora, multum ille et terrÄ«s iactÄtus et altÅ", "4. vÄ« superum saevae memorem IÅ«nÅnis ob Ä«ram;", "5. multa quoque et bellÅ passus, dum conderet urbem,", "6. inferretque deÅs LatiÅ, genus unde LatÄ«num,", "7. AlbÄnÄ«que patrÄ“s, atque altae moenia RÅmae.", "8. MÅ«sa, mihÄ« causÄs memorÄ, quÅ nÅ«mine laesÅ,", "9. quidve dolÄ“ns, rÄ“gÄ«na deum tot volvere cÄsÅ«s", "10. Ä«nsÄ«gnem pietÄte virum, tot adÄ«re labÅrÄ“s", "11. impulerit. Tantaene animÄ«s caelestibus Ä«rae?"]
    for v in versos: st.markdown(f'<p class="verse-line">{v}</p>', unsafe_allow_html=True)
    st.caption(t["sticky_note"])

with col_chat:
    st.subheader(t["chat_header"])
    chat_container = st.container(height=550, border=True)

    if "messages" not in st.session_state or len(st.session_state.messages) == 0:
        st.session_state.messages = [{"role": "assistant", "content": t["welcome"]}]

    with chat_container:
        for m in st.session_state.messages:
            with st.chat_message(m["role"]): st.markdown(m["content"])

    if prompt := st.chat_input(t["input_placeholder"]):
        # 1. AÃ±adimos el mensaje del usuario al estado
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # 2. Mostramos inmediatamente el mensaje en la UI
        with chat_container:
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.chat_message("assistant"):
                # --- CORRECCIÃ“N CRÃTICA: MAPEO DE ROLES ---
                # Gemini no acepta "assistant", solo "model".
                history_for_api = []
                for m in st.session_state.messages[:-1]:
                    api_role = "model" if m["role"] == "assistant" else "user"
                    history_for_api.append({"role": api_role, "parts": [m["content"]]})
                
                # Preparamos la consulta con refuerzo de contexto
                full_query = (
                    f"[Language: {idioma_app}] "
                    f"[MANDATO: Ignora espaÃ±ol para homÃ³grafos. Solo LatÃ­n de Virgilio. "
                    f"Foco: Significado filolÃ³gico contextual. SÃ© breve.] "
                    f"{prompt}"
                )
                
                try:
                    chat = model.start_chat(history=history_for_api)
                    with st.spinner(t["spinner"]):
                        response = chat.send_message(full_query)
                        st.markdown(response.text)
                        # Guardamos con el rol de Streamlit
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    st.error(f"{t['error_api']} (Detalle: {str(e)})")
        
        # Rerun controlado para refrescar el contenedor
        st.rerun()

    st.divider()
    st.link_button(t["cta_btn"], "https://docs.google.com/forms/d/...", use_container_width=True, type="primary")
