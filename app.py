import streamlit as st
import google.generativeai as genai
import requests

# 1. TRADUCCIONES Y FRONTEND MULTILINGÃœE
TRADUCCIONES = {
    "EspaÃ±ol": {
        "sidebar": "ğŸ›ï¸ ConfiguraciÃ³n", "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "welcome": "### ğŸ›ï¸ Salve!\nÂ¿QuÃ© palabra o verso deseas analizar?",
        "input": "PregÃºntale a la IA (ej. cano, arma, virum...)", "spinner": "Analizando...",
        "sticky": "ğŸ“ Texto fijo."
    },
    "ç¹é«”ä¸­æ–‡ (Taiwan)": {
        "sidebar": "ğŸ›ï¸ è¨­å®š", "header": "ç¶­å‰çˆ¾ï¼šã€ŠåŸƒæ¶…é˜¿æ–¯ç´€ã€‹(I, 1-11)",
        "welcome": "### ğŸ›ï¸ æ‚¨å¥½ï¼\næ‚¨æƒ³åˆ†ææ–‡ä¸­çš„å“ªå€‹è©æˆ–å“ªä¸€è¡Œï¼Ÿ",
        "input": "è©¢å• AI é—œæ–¼æ­¤æ–‡æœ¬çš„å•é¡Œ...", "spinner": "åˆ†æä¸­...",
        "sticky": "ğŸ“ æ–‡æœ¬å·²å›ºå®šã€‚"
    } # Puedes aÃ±adir English y Latine siguiendo este esquema
}

st.set_page_config(page_title="Aeneis Tutor AI", layout="wide")

# CSS para Scroll Independiente y Columna Fija
st.markdown("""
    <style>
    [data-testid="column"]:nth-of-type(1) { position: sticky; top: 2rem; align-self: flex-start; }
    .verse-line { font-family: 'Times New Roman', serif; font-size: 1.4rem; line-height: 1.7; color: #2c3e50; }
    </style>
    """, unsafe_allow_html=True)

with st.sidebar:
    idioma = st.selectbox("Language / Idioma", list(TRADUCCIONES.keys()))
    t = TRADUCCIONES[idioma]
    if st.button("ğŸ”„ Reset"):
        st.session_state.messages = []
        st.rerun()

# 2. CONFIGURACIÃ“N DE IA
@st.cache_data
def load_prompt(url):
    try:
        r = requests.get(url)
        return r.text if r.status_code == 200 else "Expert Latin Philologist."
    except: return "Expert Latin Philologist."

PROMPT_URL = "https://raw.githubusercontent.com/tu_usuario/tu_repo/main/prompt_maestro.txt"
sys_prompt = load_prompt(PROMPT_URL)

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash-lite-preview-02-05", #
        system_instruction=sys_prompt
    )
else:
    st.error("API KEY missing.")
    st.stop()

# 3. INTERFAZ DIVIDIDA
col_txt, col_chat = st.columns([1, 1], gap="large")

with col_txt:
    st.markdown(f"### {t['header']}")
    versos = [
        "1. Arma virumque canÅ, TrÅiae quÄ« prÄ«mus ab ÅrÄ«s",
        "2. Äªtaliam, fÄtÅ profugus, LÄvÄ«niaque vÄ“nit",
        "3. lÄ«tora, multum ille et terrÄ«s iactÄtus et altÅ",
        "4. vÄ« superum saevae memorem IÅ«nÅnis ob Ä«ram;",
        "5. multa quoque et bellÅ passus, dum conderet urbem,",
        "6. inferretque deÅs LatiÅ, genus unde LatÄ«num,",
        "7. AlbÄnÄ«que patrÄ“s, atque altae moenia RÅmae.",
        "8. MÅ«sa, mihÄ« causÄs memorÄ, quÅ nÅ«mine laesÅ,",
        "9. quidve dolÄ“ns, rÄ“gÄ«na deum tot volvere cÄsÅ«s",
        "10. Ä«nsÄ«gnem pietÄte virum, tot adÄ«re labÅrÄ“s",
        "11. impulerit. Tantaene animÄ«s caelestibus Ä«rae?"
    ]
    for v in versos: st.markdown(f'<p class="verse-line">{v}</p>', unsafe_allow_html=True)
    st.caption(t["sticky"])

with col_chat:
    chat_container = st.container(height=600, border=True)
    if "messages" not in st.session_state or not st.session_state.messages:
        st.session_state.messages = [{"role": "assistant", "content": t["welcome"]}]

    with chat_container:
        for m in st.session_state.messages:
            with st.chat_message(m["role"]): st.markdown(m["content"])

    if user_input := st.chat_input(t["input"]):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with chat_container:
            with st.chat_message("user"): st.markdown(user_input)
            with st.chat_message("assistant"):
                # INYECCIÃ“N DE REFUERZO: Obligamos a la IA a recordar el contexto latino y brevedad
                context_injection = f"[Idioma: {idioma}] [MANDATO: Ignora espaÃ±ol. Solo LatÃ­n de Virgilio. SÃ© breve.] {user_input}"
                
                history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages[:-1]]
                chat = model.start_chat(history=history)
                try:
                    with st.spinner(t["spinner"]):
                        response = chat.send_message(context_injection)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception:
                    st.error("Rate Limit reached.")
        st.rerun()
