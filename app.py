import streamlit as st
import google.generativeai as genai
import requests
import pandas as pd # Necesario para manejar los datos
from streamlit_gsheets import GSheetsConnection

# --- 1. CONFIGURACIÃ“N DE LA PÃGINA ---
st.set_page_config(
    page_title="Aeneis Tutor AI",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ---------------------------------------------------------
# ğŸš¨ CONFIGURACIÃ“N DE LA BASE DE DATOS (Â¡EDITA ESTO!)
# ---------------------------------------------------------
# Pega aquÃ­ el enlace de tu Google Sheet (la que compartiste con el robot)
URL_HOJA_CALCULO = "https://docs.google.com/spreadsheets/d/1022thHT1sGmNBhYdty1lXLELSK6MYQWc1GaMILlzZtQ/edit?usp=sharing"

# --- 2. DICCIONARIO DE TRADUCCIONES (Frontend) ---
TRADUCCIONES = {
    "EspaÃ±ol": {
        "sidebar_title": "ğŸ›ï¸ ConfiguraciÃ³n",
        "lang_label": "Idioma del Tutor:",
        "reset_btn": "ğŸ”„ Reiniciar Consulta",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Consulta FilolÃ³gica Libre",
        "welcome": "### ğŸ›ï¸ Â¡Salve!\nHe configurado mi sistema para ayudarte en **EspaÃ±ol**. Â¿QuÃ© palabra o verso deseas analizar?",
        "input_placeholder": "PregÃºntale a la IA (ej. cano, arma, virum...)",
        "spinner": "Analizando...",
        "error_api": "ğŸ›ï¸ El orÃ¡culo estÃ¡ saturado. Espera un momento.",
        "sticky_note": "ğŸ“ Texto fijo para consulta permanente.",
        "cta_btn": "ğŸ›ï¸ Reserva una clase con un profesor de latÃ­n"
    },
    "English": {
        "sidebar_title": "ğŸ›ï¸ Settings",
        "lang_label": "Tutor Language:",
        "reset_btn": "ğŸ”„ Reset Chat",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Free Philological Consultation",
        "welcome": "### ğŸ›ï¸ Salve!\nI have configured my system to help you in **English**. Which word or verse would you like to analyze?",
        "input_placeholder": "Ask the AI (e.g., cano, arma, virum...)",
        "spinner": "Analyzing...",
        "error_api": "ğŸ›ï¸ The oracle is busy. Please wait.",
        "sticky_note": "ğŸ“ Static text for permanent reference.",
        "cta_btn": "ğŸ›ï¸ Book a class with a Latin teacher"
    },
    "Latine": {
        "sidebar_title": "ğŸ›ï¸ Configuratio",
        "lang_label": "Lingua Tutoris:",
        "reset_btn": "ğŸ”„ Iterare Colloquium",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Colloquium Philologicum Liberum",
        "welcome": "### ğŸ›ï¸ Salve!\nSÄ«stÄ“ma meum parÄvÄ« ut **LatinÄ“** tÄ“ adiuvÄrem. Quod verbum aut versum explÅrÄre vÄ«s?",
        "input_placeholder": "InterrogÄ aliquid (ex. cano, arma, virum...)",
        "spinner": "ExquÄ«rentem...",
        "error_api": "ğŸ›ï¸ ÅŒrÄculum occupÄtum est. PaulÅ post sevÄ“rÄ.",
        "sticky_note": "ğŸ“ Textus fÄ«xus.",
        "cta_btn": "ğŸ›ï¸ Scholam cum magistro linguae Latinae reserva"
    },
    "ç¹é«”ä¸­æ–‡ (Taiwan)": {
        "sidebar_title": "ğŸ›ï¸ è¨­å®š",
        "lang_label": "å°å¸«èªè¨€ï¼š",
        "reset_btn": "ğŸ”„ é‡ç½®å°è©±",
        "header": "ç¶­å‰çˆ¾ï¼šã€ŠåŸƒæ¶…é˜¿æ–¯ç´€ã€‹(I, 1-11)",
        "chat_header": "ğŸ’¬ è‡ªç”±æ–‡ç»å­¸è«®è©¢",
        "welcome": "### ğŸ›ï¸ æ‚¨å¥½ï¼\næˆ‘å·²æº–å‚™å¥½ä»¥ **ç¹é«”ä¸­æ–‡** ç‚ºæ‚¨æä¾›å¹«åŠ©ã€‚æ‚¨æƒ³åˆ†ææ–‡ä¸­çš„å“ªå€‹è©æˆ–å“ªä¸€è¡Œï¼Ÿ",
        "input_placeholder": "å‘ AI è©¢å•ï¼ˆä¾‹å¦‚ï¼šcano, arma, virum...ï¼‰",
        "spinner": "åˆ†æä¸­...",
        "error_api": "ğŸ›ï¸ ç¥è«­ç›®å‰ç¹å¿™ã€‚è«‹ç¨å¾Œå†è©¦ã€‚",
        "sticky_note": "ğŸ“ æ–‡æœ¬å·²å›ºå®šã€‚",
        "cta_btn": "ğŸ›ï¸ èˆ‡æ‹‰ä¸èªè€å¸«é ç´„èª²ç¨‹"
    }
}

# --- 3. FUNCIONES DE MEMORIA (CEREBRO HÃBRIDO) ---

def buscar_en_base_datos(pregunta_usuario):
    """Busca si la pregunta ya existe en la hoja de cÃ¡lculo."""
    try:
        # 1. Conectamos
        conn = st.connection("gsheets", type=GSheetsConnection)
        # 2. Leemos la hoja (siempre fresca)
        df = conn.read(spreadsheet=URL_HOJA_CALCULO, usecols=[0, 1])
        
        # 3. Limpiamos datos para comparar (todo a minÃºsculas)
        pregunta_usuario = pregunta_usuario.lower().strip()
        
        # 4. Buscamos coincidencia
        # Iteramos por las filas buscando si la palabra clave estÃ¡ en la pregunta guardada
        for index, row in df.iterrows():
            pregunta_db = str(row.iloc[0]).lower()
            respuesta_db = str(row.iloc[1])
            
            # LÃ³gica simple: Si lo que escribe el usuario coincide mucho con lo guardado
            if pregunta_usuario == pregunta_db or pregunta_usuario in pregunta_db:
                return respuesta_db
        return None
    except Exception as e:
        # Si falla la conexiÃ³n, no rompemos la app, solo devolvemos None (y usaremos Gemini)
        print(f"Error DB: {e}") 
        return None

def guardar_nueva_entrada(pregunta, respuesta):
    """Guarda lo que la IA generÃ³ para no tener que volver a preguntarlo."""
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        df = conn.read(spreadsheet=URL_HOJA_CALCULO, usecols=[0, 1])
        
        # Creamos la nueva fila
        nueva_fila = pd.DataFrame([[pregunta, respuesta]], columns=df.columns)
        
        # AÃ±adimos al final
        df_actualizado = pd.concat([df, nueva_fila], ignore_index=True)
        
        # Subimos a la nube
        conn.update(spreadsheet=URL_HOJA_CALCULO, data=df_actualizado)
    except Exception as e:
        st.error(f"Error guardando memoria: {e}")

# --- 4. CSS Y DISEÃ‘O ---
st.markdown("""
    <style>
    [data-testid="column"]:nth-of-type(1) { position: sticky; top: 2rem; align-self: flex-start; }
    .verse-line { font-family: 'Times New Roman', serif; font-size: 1.4rem; line-height: 1.7; color: #2c3e50; }
    .main-header { color: #8e44ad; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# --- 5. SIDEBAR ---
with st.sidebar:
    idioma_app = st.selectbox("Language / Idioma / èªè¨€", list(TRADUCCIONES.keys()))
    t = TRADUCCIONES[idioma_app]
    st.title(t["sidebar_title"])
    if st.button(t["reset_btn"]):
        st.session_state.messages = []
        st.rerun()

    st.divider()
    # PequeÃ±o monitor de estado de la base de datos
    with st.expander("ğŸ’¾ Estado de Memoria"):
        try:
            conn = st.connection("gsheets", type=GSheetsConnection)
            df_check = conn.read(spreadsheet=URL_HOJA_CALCULO, usecols=[0,1])
            st.success(f"Conectado: {len(df_check)} respuestas aprendidas.")
        except:
            st.warning("Desconectado de la Base de Datos")

# --- 6. CONFIGURACIÃ“N DE GEMINI API ---
@st.cache_data
def load_prompt(url):
    try:
        r = requests.get(url)
        return r.text if r.status_code == 200 else "Expert Latin Philologist Role."
    except: return "Expert Latin Philologist Role."

PROMPT_URL = "https://raw.githubusercontent.com/tu_usuario/tu_repo/main/prompt_maestro.txt"
sys_instruction = load_prompt(PROMPT_URL)

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash-lite-preview-02-05",
        system_instruction=sys_instruction
    )
else:
    st.error("âš ï¸ API KEY missing in Secrets.")
    st.stop()

# --- 7. INTERFAZ PRINCIPAL ---
col_txt, col_chat = st.columns([1, 1], gap="large")

with col_txt:
    st.markdown(f"<h2 class='main-header'>{t['header']}</h2>", unsafe_allow_html=True)
    st.write("---")
    versos = ["1. Arma virumque canÅ, TrÅiae quÄ« prÄ«mus ab ÅrÄ«s", "2. Äªtaliam, fÄtÅ profugus, LÄvÄ«niaque vÄ“nit", "3. lÄ«tora, multum ille et terrÄ«s iactÄtus et altÅ", "4. vÄ« superum saevae memorem IÅ«nÅnis ob Ä«ram;", "5. multa quoque et bellÅ passus, dum conderet urbem,", "6. inferretque deÅs LatiÅ, genus unde LatÄ«num,", "7. AlbÄnÄ«que patrÄ“s, atque altae moenia RÅmae.", "8. MÅ«sa, mihÄ« causÄs memorÄ, quÅ nÅ«mine laesÅ,", "9. quidve dolÄ“ns, rÄ“gÄ«na deum tot volvere cÄsÅ«s", "10. Ä«nsÄ«gnem pietÄte virum, tot adÄ«re labÅrÄ“s", "11. impulerit. Tantaene animÄ«s caelestibus Ä«rae?"]
    for v in versos: st.markdown(f'<p class="verse-line">{v}</p>', unsafe_allow_html=True)
    st.caption(t["sticky_note"])

with col_chat:
    st.subheader(t["chat_header"])
    chat_container = st.container(height=550, border=True)

    if "messages" not in st.session_state or len(st.session_state.messages) == 0:
        st.session_state.messages = [{"role": "assistant", "content": t["welcome"]}]

    with chat_container:
        for m in st.session_state.messages:
            with st.chat_message(m["role"]): st.markdown(m["content"])

    # --- 8. LÃ“GICA DEL CHAT INTELIGENTE ---
    if prompt := st.chat_input(t["input_placeholder"]):
        # A) Mostrar lo que el usuario escribiÃ³
        st.session_state.messages.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.chat_message("assistant"):
                
                # --- PASO 1: BUSCAR EN LA BASE DE DATOS (GRATIS) ---
                respuesta_guardada = buscar_en_base_datos(prompt)
                
                if respuesta_guardada:
                    # Â¡Ã‰XITO! Encontramos la respuesta en el Excel
                    st.success("ğŸ“š Respuesta recuperada de tu Base de Conocimiento")
                    st.markdown(respuesta_guardada)
                    st.session_state.messages.append({"role": "assistant", "content": respuesta_guardada})
                
                else:
                    # --- PASO 2: PREGUNTAR A GEMINI (COSTE API) ---
                    # No estaba guardada, asÃ­ que llamamos a la IA
                    
                    # Preparar historial (Sliding Window)
                    LIMITE_MEMORIA = 6 
                    mensajes_recientes = st.session_state.messages[-LIMITE_MEMORIA:]
                    history_for_api = []
                    for m in mensajes_recientes[:-1]: 
                        api_role = "model" if m["role"] == "assistant" else "user"
                        history_for_api.append({"role": api_role, "parts": [m["content"]]})
                    
                    full_query = (
                        f"[Language: {idioma_app}] "
                        f"[MANDATO: Ignora espaÃ±ol para homÃ³grafos. Solo LatÃ­n de Virgilio. "
                        f"Foco: Significado filolÃ³gico contextual. SÃ© breve y directo.] "
                        f"{prompt}"
                    )
                    
                    try:
                        chat = model.start_chat(history=history_for_api)
                        with st.spinner(t["spinner"]):
                            response = chat.send_message(full_query)
                            texto_ia = response.text
                            
                            # Mostrar respuesta
                            st.markdown(texto_ia)
                            st.session_state.messages.append({"role": "assistant", "content": texto_ia})
                            
                            # --- PASO 3: GUARDAR PARA EL FUTURO ---
                            # Guardamos en Google Sheets automÃ¡ticamente
                            with st.status("ğŸ“ Aprendiendo nuevo concepto...", expanded=False):
                                guardar_nueva_entrada(prompt, texto_ia)
                                st.write("Â¡Guardado en la base de datos!")
                                
                    except Exception as e:
                        st.error(f"{t['error_api']} ({str(e)})")
        
        # Recargamos para actualizar estado
        st.rerun()

    st.divider()
    form_url = "https://docs.google.com/forms/d/e/1FAIpQLSdcEGs0k3eO1A3yDwwlRPZxM7RPpOPVD121J6GMUwAgbtbQ5w/viewform?usp=header"
    st.link_button(t["cta_btn"], form_url, use_container_width=True, type="primary")
