import streamlit as st
import google.generativeai as genai
import requests
import pandas as pd
from streamlit_gsheets import GSheetsConnection

# --- 1. CONFIGURACIÃ“N DE LA PÃGINA ---
st.set_page_config(
    page_title="Aeneis Tutor AI",
    page_icon="ğŸ›ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- CONFIGURACIÃ“N DE LA BASE DE DATOS ---
URL_HOJA_CALCULO = "https://docs.google.com/spreadsheets/d/1022thHT1sGmNBhYdty1lXLELSK6MYQWc1GaMILlzZtQ/edit?usp=sharing"

# --- 2. DICCIONARIO DE TRADUCCIONES ---
TRADUCCIONES = {
    "EspaÃ±ol": {
        "sidebar_title": "ğŸ›ï¸ ConfiguraciÃ³n",
        "lang_label": "Idioma del Tutor:",
        "reset_btn": "ğŸ”„ Reiniciar Consulta",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Consulta FilolÃ³gica Libre",
        "welcome": "### ğŸ›ï¸ Â¡Salve!\nHe configurado mi sistema para ayudarte en **EspaÃ±ol**. Â¿QuÃ© palabra o verso deseas analizar?",
        "input_placeholder": "PregÃºntale a la IA (ej. cano, arma, virum...)",
        "spinner": "Analizando...",
        "error_api": "ğŸ›ï¸ El orÃ¡culo estÃ¡ saturado. Espera un momento.",
        "sticky_note": "ğŸ“ Texto fijo para consulta permanente.",
        "cta_btn": "ğŸ›ï¸ Reserva una clase con un profesor de latÃ­n"
    },
    "English": {"sidebar_title": "Settings", "lang_label": "Language:", "reset_btn": "Reset", "header": "Aeneid (I, 1-11)", "chat_header": "Consultation", "welcome": "### Salve!", "input_placeholder": "Ask...", "spinner": "...", "error_api": "Error", "sticky_note": "Note", "cta_btn": "Book Class"},
    "Latine": {"sidebar_title": "Configuratio", "lang_label": "Lingua:", "reset_btn": "Iterare", "header": "Aeneid (I, 1-11)", "chat_header": "Colloquium", "welcome": "### Salve!", "input_placeholder": "InterrogÄ...", "spinner": "...", "error_api": "Error", "sticky_note": "Nota", "cta_btn": "Schola"},
    "ç¹é«”ä¸­æ–‡ (Taiwan)": {"sidebar_title": "è¨­å®š", "lang_label": "èªè¨€:", "reset_btn": "é‡ç½®", "header": "ç¶­å‰çˆ¾ï¼šã€ŠåŸƒæ¶…é˜¿æ–¯ç´€ã€‹", "chat_header": "è«®è©¢", "welcome": "### æ‚¨å¥½!", "input_placeholder": "è©¢å•...", "spinner": "...", "error_api": "éŒ¯èª¤", "sticky_note": "å‚™è¨»", "cta_btn": "é ç´„"}
}

# --- 3. FUNCIONES DE MEMORIA (CEREBRO HÃBRIDO) ---

def buscar_en_base_datos(pregunta_usuario):
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        df = conn.read(spreadsheet=URL_HOJA_CALCULO, ttl=0)
        df = df.dropna(how="all").fillna("")
        
        pregunta_usuario = pregunta_usuario.lower().strip()
        
        for index, row in df.iterrows():
            # Buscamos en la primera columna (Pregunta)
            pregunta_db = str(row.iloc[0]).lower().strip()
            respuesta_db = str(row.iloc[1])
            
            if not pregunta_db: continue
            
            # BÃºsqueda flexible
            if (pregunta_usuario in pregunta_db) or (pregunta_db in pregunta_usuario):
                return respuesta_db
        return None
    except: return None

def guardar_nueva_entrada(pregunta, respuesta):
    try:
        conn = st.connection("gsheets", type=GSheetsConnection)
        df = conn.read(spreadsheet=URL_HOJA_CALCULO, ttl=0)
        df = df.dropna(how="all")
        
        nueva_fila = pd.DataFrame([[pregunta, respuesta]], columns=df.columns)
        df_actualizado = pd.concat([df, nueva_fila], ignore_index=True)
        
        conn.update(spreadsheet=URL_HOJA_CALCULO, data=df_actualizado)
        return True
    except: return False

# --- 4. DISEÃ‘O ---
st.markdown("""
    <style>
    [data-testid="column"]:nth-of-type(1) { position: sticky; top: 2rem; align-self: flex-start; }
    .verse-line { font-family: 'Times New Roman', serif; font-size: 1.4rem; line-height: 1.7; color: #2c3e50; }
    .main-header { color: #8e44ad; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# --- 5. SIDEBAR ---
with st.sidebar:
    idioma_app = st.selectbox("Language / Idioma / èªè¨€", list(TRADUCCIONES.keys()))
    t = TRADUCCIONES[idioma_app]
    st.title(t["sidebar_title"])
    if st.button(t["reset_btn"]):
        st.session_state.messages = []
        st.cache_data.clear()
        st.rerun()

# --- 6. CONFIGURACIÃ“N GEMINI ---
@st.cache_data
def load_prompt(url):
    try:
        r = requests.get(url)
        return r.text if r.status_code == 200 else "Expert Latin Philologist."
    except: return "Expert Latin Philologist."

PROMPT_URL = "https://raw.githubusercontent.com/tu_usuario/tu_repo/main/prompt_maestro.txt"
sys_instruction = load_prompt(PROMPT_URL)

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel(model_name="gemini-2.0-flash-lite-preview-02-05", system_instruction=sys_instruction)
else:
    st.error("âš ï¸ API KEY missing.")
    st.stop()

# --- 7. INTERFAZ ---
col_txt, col_chat = st.columns([1, 1], gap="large")

with col_txt:
    st.markdown(f"<h2 class='main-header'>{t['header']}</h2>", unsafe_allow_html=True)
    st.write("---")
    versos = ["1. Arma virumque canÅ, TrÅiae quÄ« prÄ«mus ab ÅrÄ«s", "2. Äªtaliam, fÄtÅ profugus, LÄvÄ«niaque vÄ“nit", "3. lÄ«tora, multum ille et terrÄ«s iactÄtus et altÅ", "4. vÄ« superum saevae memorem IÅ«nÅnis ob Ä«ram;", "5. multa quoque et bellÅ passus, dum conderet urbem,", "6. inferretque deÅs LatiÅ, genus unde LatÄ«num,", "7. AlbÄnÄ«que patrÄ“s, atque altae moenia RÅmae.", "8. MÅ«sa, mihÄ« causÄs memorÄ, quÅ nÅ«mine laesÅ,", "9. quidve dolÄ“ns, rÄ“gÄ«na deum tot volvere cÄsÅ«s", "10. Ä«nsÄ«gnem pietÄte virum, tot adÄ«re labÅrÄ“s", "11. impulerit. Tantaene animÄ«s caelestibus Ä«rae?"]
    for v in versos: st.markdown(f'<p class="verse-line">{v}</p>', unsafe_allow_html=True)
    st.caption(t["sticky_note"])

with col_chat:
    st.subheader(t["chat_header"])
    chat_container = st.container(height=550, border=True)

    if "messages" not in st.session_state or len(st.session_state.messages) == 0:
        st.session_state.messages = [{"role": "assistant", "content": t["welcome"]}]

    with chat_container:
        for m in st.session_state.messages:
            with st.chat_message(m["role"]): st.markdown(m["content"])

    if prompt := st.chat_input(t["input_placeholder"]):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"): st.markdown(prompt)
            
            with st.chat_message("assistant"):
                # BUSCAR EN DB
                respuesta_db = buscar_en_base_datos(prompt)
                
                if respuesta_db:
                    st.success("ğŸ“š Respuesta de la Base de Conocimiento")
                    st.markdown(respuesta_db)
                    st.session_state.messages.append({"role": "assistant", "content": respuesta_db})
                else:
                    # CONSULTAR IA
                    try:
                        history = [{"role": "model" if m["role"]=="assistant" else "user", "parts": [m["content"]]} 
                                   for m in st.session_state.messages[-6:-1]]
                        full_query = f"[Language: {idioma_app}] {prompt}"
                        chat = model.start_chat(history=history)
                        with st.spinner(t["spinner"]):
                            response = chat.send_message(full_query)
                            texto_ia = response.text
                            st.markdown(texto_ia)
                            st.session_state.messages.append({"role": "assistant", "content": texto_ia})
                            # GUARDAR
                            with st.status("ğŸ“ Guardando...", expanded=False):
                                guardar_nueva_entrada(prompt, texto_ia)
                    except Exception as e:
                        st.error(f"Error: {str(e)}")
        st.rerun()

    st.divider()
    form_url = "https://docs.google.com/forms/d/e/1FAIpQLSdcEGs0k3eO1A3yDwwlRPZxM7RPpOPVD121J6GMUwAgbtbQ5w/viewform?usp=header"
    st.link_button(t["cta_btn"], form_url, use_container_width=True, type="primary")
