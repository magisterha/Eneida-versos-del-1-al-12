import streamlit as st
import google.generativeai as genai
import requests

# 1. DICCIONARIO DE TRADUCCIONES PARA EL FRONTEND
TRADUCCIONES = {
    "EspaÃ±ol": {
        "sidebar_title": "ğŸ›ï¸ ConfiguraciÃ³n",
        "lang_label": "Idioma del Tutor:",
        "reset_btn": "ğŸ”„ Reiniciar Consulta",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Consulta FilolÃ³gica Libre",
        "welcome": "### ğŸ›ï¸ Â¡Salve!\nHe configurado mi sistema para ayudarte en **EspaÃ±ol**. Â¿QuÃ© palabra o verso deseas analizar?",
        "input_placeholder": "PregÃºntale cualquier cosa de este texto a la IA",
        "spinner": "Analizando bajo contexto...",
        "error_api": "ğŸ›ï¸ El orÃ¡culo estÃ¡ saturado. Reintenta en breve.",
        "sticky_note": "ğŸ“ Texto fijo para consulta permanente."
    },
    "English": {
        "sidebar_title": "ğŸ›ï¸ Settings",
        "lang_label": "Tutor Language:",
        "reset_btn": "ğŸ”„ Reset Chat",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Free Philological Consultation",
        "welcome": "### ğŸ›ï¸ Salve!\nI have configured my system to help you in **English**. Which word or verse would you like to analyze?",
        "input_placeholder": "Ask the AI anything about this text",
        "spinner": "Analyzing contextually...",
        "error_api": "ğŸ›ï¸ The oracle is busy. Please try again in a moment.",
        "sticky_note": "ğŸ“ Static text for permanent reference."
    },
    "Latine": {
        "sidebar_title": "ğŸ›ï¸ Configuratio",
        "lang_label": "Lingua Tutoris:",
        "reset_btn": "ğŸ”„ Iterare Colloquium",
        "header": "P. Vergili Maronis: Aeneis (I, 1-11)",
        "chat_header": "ğŸ’¬ Colloquium Philologicum Liberum",
        "welcome": "### ğŸ›ï¸ Salve!\nSÄ«stÄ“ma meum parÄvÄ« ut **LatinÄ“** tÄ“ adiuvÄrem. Quod verbum aut versum explÅrÄre vÄ«s?",
        "input_placeholder": "InterrogÄ aliquid dÄ“ hÅc textÅ«",
        "spinner": "ExquÄ«rentem...",
        "error_api": "ğŸ›ï¸ ÅŒrÄculum occupÄtum est. PaulÅ post sevÄ“rÄ.",
        "sticky_note": "ğŸ“ Textus fÄ«xus ad perpetuam cÅnsultÄtiÅnem."
    },
    "ç¹é«”ä¸­æ–‡ (Taiwan)": {
        "sidebar_title": "ğŸ›ï¸ è¨­å®š",
        "lang_label": "å°å¸«èªè¨€ï¼š",
        "reset_btn": "ğŸ”„ é‡ç½®å°è©±",
        "header": "ç¶­å‰çˆ¾ï¼šã€ŠåŸƒæ¶…é˜¿æ–¯ç´€ã€‹(I, 1-11)",
        "chat_header": "ğŸ’¬ è‡ªç”±æ–‡ç»å­¸è«®è©¢",
        "welcome": "### ğŸ›ï¸ æ‚¨å¥½ (Salve)ï¼\næˆ‘å·²æº–å‚™å¥½ä»¥ **ç¹é«”ä¸­æ–‡** ç‚ºæ‚¨æä¾›å¹«åŠ©ã€‚æ‚¨æƒ³åˆ†ææ–‡ä¸­çš„å“ªå€‹è©æˆ–å“ªä¸€è¡Œï¼Ÿ",
        "input_placeholder": "å‘ AI è©¢å•é—œæ–¼æ­¤æ–‡æœ¬çš„ä»»ä½•å•é¡Œ",
        "spinner": "æ­£åœ¨é€²è¡Œèªå¢ƒåˆ†æ...",
        "error_api": "ğŸ›ï¸ ç¥è«­ç›®å‰ç¹å¿™ã€‚è«‹ç¨å¾Œå†è©¦ã€‚",
        "sticky_note": "ğŸ“ æ–‡æœ¬å·²å›ºå®šï¼Œæ–¹ä¾¿éš¨æ™‚æŸ¥é–±ã€‚"
    }
}

# 2. CONFIGURACIÃ“N DE PÃGINA Y CSS
st.set_page_config(page_title="Aeneis Tutor AI", layout="wide")

st.markdown("""
    <style>
    [data-testid="column"]:nth-of-type(1) { position: sticky; top: 2rem; align-self: flex-start; }
    .verse-line { font-family: 'Times New Roman', serif; font-size: 1.4rem; line-height: 1.7; color: #2c3e50; }
    .main-header { color: #8e44ad; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# 3. SIDEBAR MULTILINGÃœE
with st.sidebar:
    # Determinamos el idioma antes de renderizar el resto
    idioma_app = st.selectbox("Language / Idioma / èªè¨€", list(TRADUCCIONES.keys()))
    t = TRADUCCIONES[idioma_app] # Alias para las traducciones actuales
    
    st.title(t["sidebar_title"])
    st.write(f"**{t['lang_label']}** {idioma_app}")
    if st.button(t["reset_btn"]):
        st.session_state.messages = []
        st.rerun()

# 4. CONFIGURACIÃ“N DE IA Y CARGA DE PROMPT
@st.cache_data
def load_prompt(url):
    try:
        r = requests.get(url)
        return r.text if r.status_code == 200 else "Expert Philologist Role."
    except: return "Expert Philologist Role."

PROMPT_URL = "https://raw.githubusercontent.com/tu_usuario/tu_repo/main/prompt_maestro.txt"
sys_instruction = load_prompt(PROMPT_URL)

if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash-lite-preview-02-05",
        system_instruction=sys_instruction
    )
else:
    st.error("âš ï¸ Configura la API KEY en Secrets.")
    st.stop()

# 5. DISEÃ‘O DIVIDIDO
col_txt, col_chat = st.columns([1, 1], gap="large")

with col_txt:
    st.markdown(f"<h2 class='main-header'>{t['header']}</h2>", unsafe_allow_html=True)
    st.write("---")
    versos = [
        "1. Arma virumque canÅ, TrÅiae quÄ« prÄ«mus ab ÅrÄ«s",
        "2. Äªtaliam, fÄtÅ profugus, LÄvÄ«niaque vÄ“nit",
        "3. lÄ«tora, multum ille et terrÄ«s iactÄtus et altÅ",
        "4. vÄ« superum saevae memorem IÅ«nÅnis ob Ä«ram;",
        "5. multa quoque et bellÅ passus, dum conderet urbem,",
        "6. inferretque deÅs LatiÅ, genus unde LatÄ«num,",
        "7. AlbÄnÄ«que patrÄ“s, atque altae moenia RÅmae.",
        "8. MÅ«sa, mihÄ« causÄs memorÄ, quÅ nÅ«mine laesÅ,",
        "9. quidve dolÄ“ns, rÄ“gÄ«na deum tot volvere cÄsÅ«s",
        "10. Ä«nsÄ«gnem pietÄte virum, tot adÄ«re labÅrÄ“s",
        "11. impulerit. Tantaene animÄ«s caelestibus Ä«rae?"
    ]
    for v in versos: st.markdown(f'<p class="verse-line">{v}</p>', unsafe_allow_html=True)
    st.caption(t["sticky_note"])

with col_chat:
    st.subheader(t["chat_header"])
    chat_container = st.container(height=600, border=True)

    if "messages" not in st.session_state or len(st.session_state.messages) == 0:
        st.session_state.messages = [{"role": "assistant", "content": t["welcome"]}]

    with chat_container:
        for m in st.session_state.messages:
            with st.chat_message(m["role"]): st.markdown(m["content"])

    if prompt := st.chat_input(t["input_placeholder"]):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"): st.markdown(prompt)
            with st.chat_message("assistant"):
                full_query = f"[Respond in: {idioma_app}] [Focus: Contextual Philology] {prompt}"
                history = [{"role": m["role"], "parts": [m["content"]]} for m in st.session_state.messages[:-1]]
                chat = model.start_chat(history=history)
                try:
                    with st.spinner(t["spinner"]):
                        response = chat.send_message(full_query)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception:
                    st.error(t["error_api"])
        st.rerun()
